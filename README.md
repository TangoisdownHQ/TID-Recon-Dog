# ğŸ›¡ï¸ TID-Recon-Dog: AI-Powered Decoy Honeypot

## ğŸ“Œ Introduction

**TID-Recon-Dog** is an advanced deception platform built to **trap**, **track**, and **analyze** malicious intrusions using a powerful blend of honeypots and **local AI agents**.

> Simulates real-world services like `SSH`, `HTTP`, `FTP`, and `PostgreSQL`, delivering highly believable responses powered by LLMs (Mistral, TinyLlama, GPT4All).  
> Logs every move an attacker makes â€” with zero exposure risk.

---

## âœ¨ Key Features

- ğŸ§  **AI-Powered Deception**  
  Local LLMs simulate system responses, banners, and output with deceptive realism.

- ğŸ›¡ï¸ **Multi-Protocol Honeypots**  
  Simulates SSH, HTTP, FTP, and PostgreSQL with authentic endpoint behavior.

- ğŸ—‚ï¸ **File Uploads & Listings**  
  Attackers can interact with fake files and directories.

- ğŸ•µï¸ **Advanced Logging**  
  IP, headers, auth attempts, uploaded files, and commands â€” geo-tagged and enriched.

- ğŸ“¡ **External Ready (DMZ / Edge)**  
  Deploy in any DMZ, network boundary, or deceptive edge.

- ğŸ§± **Modular & AI-Pluggable**  
  Switch AI models, rotate fake content, and extend new services easily.

---

## ğŸ’¼ Enterprise & Cloud Use

| Feature                     | Supported |
|----------------------------|-----------|
| ğŸŒ DMZ / Perimeter Deploy  | âœ…         |
| ğŸ³ Docker / Compose Ready  | âœ…         |
| â˜ï¸ Cloud-Native (K8s)      | âœ…         |
| ğŸ§  Local LLMs (Offline)    | âœ…         |
| ğŸ“Š SIEM Integrations (WIP) | âœ…         |

---

## ğŸ’¡ Use Cases

- Threat Intelligence Gathering  
- Honeynet Deployments  
- Red Team / Blue Team Defense  
- AI/LLM Deception Research  
- Early-Stage Recon / Fingerprinting  
- Endpoint Simulation in Wargames

---

## ğŸ“¦ Tech Stack

- **Node.js / TypeScript**  
- **LangChain + Mistral, TinyLlama, GPT4All**  
- **Docker / Kubernetes / LM Studio / Ollama**  
- **Pino (Logging), Express.js, FTP-Srv**

---

## ğŸ“‚ Project Structure


TID-Recon-Dog/
â”‚â”€â”€ dist/                 # Compiled TypeScript output
â”‚â”€â”€ logs/                 # Stored logs from interactions
â”‚â”€â”€ models/               # AI models (Mistral, GPT4All)
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ httpService.ts  # HTTP honeypot
â”‚   â”‚   â”œâ”€â”€ sshService.ts   # SSH honeypot
â”‚   â”‚   â”œâ”€â”€ ftpService.ts   # FTP honeypot
â”‚   â”‚   â”œâ”€â”€ dbService.ts    # PostgreSQL honeypot
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ aiAgent.ts      # AI response engine
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.ts       # Logging system
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.ts       # Configuration file
â”‚   â”œâ”€â”€ index.ts            # Entry point
â”‚â”€â”€ docker-compose.yml      # Docker setup
â”‚â”€â”€ Dockerfile              # Docker build instructions
â”‚â”€â”€ package.json            # Dependencies
â”‚â”€â”€ tsconfig.json           # TypeScript settings
â”‚â”€â”€ README.md               # Documentation



---

## ğŸš€ Getting Started (Local)

### 1. Clone & Install
```bash
git clone https://github.com/TangoisdownHQ/TID-Recon-Dog.git
cd TID-Recon-Dog
npm install

2. Build TypeScript
npx tsc

3. Run Locally
node dist/index.js

ğŸ³ Docker Deployment
docker-compose up --build -d
View logs: docker logs -f tid-recon-dog

Stop: docker-compose down

â˜ï¸ Kubernetes Deployment
Deploy TID-Recon-Dog as a microservice in your Kubernetes honeynet cluster.
1. Expose via Ingress / NodePort

ğŸŒ Web-Exposed Services
Service	Port
HTTP	3000
SSH	2222
FTP	2121
PostgreSQL	5432
You can expose them via ngrok, reverse proxy, or Kubernetes ingress.

ğŸ§  AI Response Engine
// src/ai_agents/aiResponder.ts

- Uses Mistral 7B, TinyLlama, or GPT4All
- Dynamically responds with fake shell output, DB logs, system banners
- Never reveals honeypot intent

ğŸ§ª Testing
curl http://localhost:3000
curl -X POST http://localhost:3000/upload
ssh fake@localhost -p 2222
ftp localhost
psql -h localhost -p 5432 -U honeypot

ğŸªµ Logs & Threat Analysis
tail -f logs/connections.log

ğŸ“¤ AI Model Configuration
Change model in config.ts or .env:

export const AI_MODEL = "mistral-7b-instruct-v0.3"; // or tinyllama, phi2
To use LM Studio:

Set base URL: http://localhost:1234/v1

Ensure LM Studio is running

Model should support chat-style roles

ğŸ“ˆ Future Roadmap
 SMB / RDP Fake Services

 Web Dashboard for Activity

 SIEM Log Forwarding (Elastic / Splunk)

 Real-time AI Threat Scoring

 Alert Webhooks / Email / Slack

 Decoy Container API tokens, Secrets

ğŸ” Licensing
This project is commercially licensed.

To request a license key, partnership, or enterprise license: ğŸ“© Email: support@yourdomain.com

ğŸ“£ Contact
ğŸ”— GitHub Issues

âœ‰ï¸ tangoisdown@Tutanota.de

ğŸ§ª Test Portal (coming soon)

âš ï¸ Legal Disclaimer
TID-Recon-Dog is for research and legal defense only.
Do not deploy in environments without proper authorization.
Use at your own risk. Complies with legal deceptive defense strategies under cybersecurity frameworks.

â­ Like This Project?
Star the repo â­
Share with Red Teams ğŸ•µï¸
Integrate it into your SOC / honeynet ğŸ“Š

